import xml.etree.ElementTree as ET
import json
import os
import email.utils
from feishu import feishu
import urllib3
from dotenv import load_dotenv
import datetime


class RssMonitor:
    """
    ä¸€ä¸ªç›‘æ§ RSS è®¢é˜…æºå¹¶æå–æ–°å†…å®¹çš„ç±»ã€‚
    """

    def __init__(self, local_storage_path: str):
        """
        åˆå§‹åŒ– RssMonitorã€‚

        å‚æ•°:
            local_storage_path (str): ç”¨äºå­˜å‚¨ RSS æ•°æ®çš„æœ¬åœ°ç›®å½•è·¯å¾„ã€‚
                                      æ•°æ®å°†ä¿å­˜åœ¨æ­¤ç›®å½•ä¸‹çš„ 'rss_feed_data.json' æ–‡ä»¶ä¸­ã€‚
        """
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()

        self.storage_path = local_storage_path
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        os.makedirs(self.storage_path, exist_ok=True)
        self.data_file_path = os.path.join(self.storage_path, "rss_feed_data.json")
        print(
            f"RssMonitor åˆå§‹åŒ–å®Œæ¯•ã€‚æ•°æ®å°†å­˜å‚¨åœ¨: {os.path.abspath(self.data_file_path)}"
        )

    def _fetch_and_parse_rss(self, rss_url: str) -> list[dict]:
        """
        ä»ç»™å®šçš„ URL è·å– RSS è®¢é˜…å†…å®¹å¹¶è§£æã€‚

        å‚æ•°:
            rss_url (str): RSS è®¢é˜…æºçš„ URLã€‚

        è¿”å›:
            list[dict]: åŒ…å«æ¡ç›®ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å« 'title', 'link', 'guid' å’Œ 'pubDate'ã€‚
                        å¦‚æœè·å–æˆ–è§£æå¤±è´¥ï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚
        """
        items = []
        try:
            import requests
            import time

            # å¿½ç•¥SSLè­¦å‘Š
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

            # åˆ›å»ºä¼šè¯ä¿æŒè¿æ¥çŠ¶æ€
            session = requests.Session()
            session.verify = False

            # ä»ç¯å¢ƒå˜é‡è·å–Cookie
            cookie = os.getenv("COOKIE", "")

            # è®¾ç½®ç±»ä¼¼çœŸå®æµè§ˆå™¨çš„headers
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36 Edg/136.0.0.0",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
                "Cache-Control": "max-age=0",
                "Referer": "https://linux.do/",
                "Cookie": cookie,
            }

            # å…ˆè®¿é—®ä¸»ç«™è·å–cookies
            session.get("https://linux.do/", headers=headers, timeout=15)

            # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
            time.sleep(2)

            # è¯·æ±‚RSSé“¾æ¥
            response = session.get(rss_url, headers=headers, timeout=15)

            if response.status_code != 200:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text[:300]}...")
                feishu(
                    "âŒ è®ºå›æ›´æ–°å¤±è´¥",
                    [
                        [
                            {
                                "tag": "text",
                                "text": f"âš ï¸ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}",
                            },
                        ],
                        [
                            {
                                "tag": "text",
                                "text": f"ğŸ“„ å“åº”å†…å®¹: {response.text[:300]}...",
                            },
                        ],
                    ],
                )
                return []

            content_str = response.text

            if not content_str.strip():
                print("è·å–åˆ°çš„RSSå†…å®¹ä¸ºç©º")
                return []

            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºXML
            if not content_str.startswith("<?xml"):
                print(f"è·å–åˆ°çš„å†…å®¹å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„XML: {content_str[:100]}...")
                # å°è¯•æŸ¥æ‰¾XMLå¼€å§‹ä½ç½®
                xml_start = content_str.find("<?xml")
                if xml_start > 0:
                    content_str = content_str[xml_start:]
                else:
                    print("æœªèƒ½æ‰¾åˆ°XMLå†…å®¹ï¼Œå¯èƒ½æ˜¯é‡åˆ°äº†äººæœºéªŒè¯")
                    print("æ­£åœ¨å°è¯•è§£å†³...")
                    # å°è¯•è§£æHTMLæŸ¥æ‰¾ä¿æŠ¤æ¨¡å¼çš„æç¤º
                    if "just a moment" in content_str.lower():
                        print("æ£€æµ‹åˆ°Cloudflareä¿æŠ¤æˆ–ç±»ä¼¼ä¿æŠ¤æœºåˆ¶")
                    return []

            # è§£æXML
            try:
                root = ET.fromstring(content_str)

                # ä¼˜å…ˆæŸ¥æ‰¾ RSS 2.0 æ ‡å‡†çš„ channel/item
                item_elements = root.findall(".//channel/item")
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯• Atom feed çš„ entry
                if not item_elements:
                    item_elements = root.findall("{http://www.w3.org/2005/Atom}entry")

                print(f"æ‰¾åˆ° {len(item_elements)} ä¸ªitemå…ƒç´ ")

                for item_element in item_elements:
                    title_element = item_element.find("title")
                    title = (
                        title_element.text.strip()
                        if title_element is not None and title_element.text
                        else "N/A"
                    )

                    link_element = item_element.find("link")
                    link = None
                    if link_element is not None:
                        if "href" in link_element.attrib:  # Atom feeds
                            link = link_element.get("href")
                        elif link_element.text:  # RSS
                            link = link_element.text

                    guid_element = item_element.find("guid")  # RSS
                    id_element = item_element.find(
                        "{http://www.w3.org/2005/Atom}id"
                    )  # Atom

                    guid = None
                    if guid_element is not None and guid_element.text:
                        guid = guid_element.text.strip()
                    elif id_element is not None and id_element.text:
                        guid = id_element.text.strip()

                    # å¦‚æœ guid ä¸å­˜åœ¨ï¼Œä½¿ç”¨ link ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
                    if not guid and link:
                        guid = link.strip()

                    # æå–å‘å¸ƒæ—¶é—´
                    pub_date_element = item_element.find("pubDate")  # RSS
                    published_element = item_element.find(
                        "{http://www.w3.org/2005/Atom}published"
                    )  # Atom

                    pub_date = None
                    if pub_date_element is not None and pub_date_element.text:
                        pub_date = pub_date_element.text.strip()
                    elif published_element is not None and published_element.text:
                        pub_date = published_element.text.strip()

                    # å‘å¸ƒæ—¶é—´è½¬åŒ–ä¸ºæ ‡å‡†ä¸œå…«åŒºæ—¶é—´ï¼Œä¾‹å¦‚å‘å¸ƒæ—¶é—´: Wed, 14 May 2025 11:05:36 +0000
                    if pub_date:
                        try:
                            # å°è¯•è§£æä¸åŒæ ¼å¼çš„æ—¶é—´
                            parsed_time = None
                            # å°è¯• RSS æ ¼å¼ (RFC 822)
                            try:
                                parsed_time = email.utils.parsedate_to_datetime(
                                    pub_date
                                )
                            except (TypeError, ValueError):
                                pass

                            # å°è¯• Atom æ ¼å¼ (ISO 8601)
                            if not parsed_time:
                                try:
                                    parsed_time = datetime.datetime.fromisoformat(
                                        pub_date.replace("Z", "+00:00")
                                    )
                                except (ValueError, AttributeError):
                                    pass

                            # å¦‚æœæˆåŠŸè§£æï¼Œè½¬æ¢ä¸ºä¸œå…«åŒºæ—¶é—´
                            if parsed_time:
                                # ç¡®ä¿æ—¶é—´æœ‰æ—¶åŒºä¿¡æ¯
                                if parsed_time.tzinfo is None:
                                    parsed_time = parsed_time.replace(
                                        tzinfo=datetime.timezone.utc
                                    )

                                # è½¬æ¢åˆ°ä¸œå…«åŒº (UTC+8)
                                china_timezone = datetime.timezone(
                                    datetime.timedelta(hours=8)
                                )
                                china_time = parsed_time.astimezone(china_timezone)

                                # æ ¼å¼åŒ–æ—¶é—´
                                pub_date = china_time.strftime("%Y-%m-%d %H:%M:%S")
                        except Exception as e:
                            print(f"æ—¶é—´è½¬æ¢é”™è¯¯: {e}, åŸå§‹æ—¶é—´: {pub_date}")

                    if title and link and guid:
                        items.append(
                            {
                                "title": title,
                                "link": link.strip(),
                                "guid": guid,
                                "pubDate": pub_date,
                            }
                        )
                    elif title and guid and not link:
                        items.append(
                            {
                                "title": title,
                                "link": "N/A",
                                "guid": guid,
                                "pubDate": pub_date,
                            }
                        )

            except ET.ParseError as e:
                print(f"è§£æ XML å¤±è´¥: {e}")
                print(f"å†…å®¹ç‰‡æ®µ: {content_str[:200]}")

        except requests.exceptions.RequestException as e:
            print(f"è¯·æ±‚å¼‚å¸¸ ({rss_url}): {e}")
        except Exception as e:
            print(f"å¤„ç† RSS æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ ({rss_url}): {e}")

        return items

    def _load_stored_item_guids(self) -> set[str]:
        """
        ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å…ˆå‰å­˜å‚¨çš„æ¡ç›®çš„ GUIDã€‚

        è¿”å›:
            set[str]: å­˜å‚¨çš„ GUID é›†åˆã€‚å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è¯»å–/è§£æï¼Œåˆ™è¿”å›ç©ºé›†åˆã€‚
        """
        stored_guids = set()
        if os.path.exists(self.data_file_path):
            try:
                with open(self.data_file_path, "r", encoding="utf-8") as f:
                    stored_items = json.load(f)
                for item in stored_items:
                    # ç¡®ä¿ 'guid' é”®å­˜åœ¨
                    if isinstance(item, dict) and "guid" in item and item["guid"]:
                        stored_guids.add(item["guid"])
            except json.JSONDecodeError:
                print(
                    f"è§£æ JSON æ–‡ä»¶ '{self.data_file_path}' å¤±è´¥ã€‚å°†è§†ä¸ºç©ºç™½å†å²è®°å½•ã€‚"
                )
            except IOError:
                print(f"è¯»å–æ–‡ä»¶ '{self.data_file_path}' å¤±è´¥ã€‚å°†è§†ä¸ºç©ºç™½å†å²è®°å½•ã€‚")
        return stored_guids

    def _save_current_items(self, items: list[dict]):
        """
        å°†å½“å‰è·å–çš„æ¡ç›®åˆ—è¡¨ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ã€‚

        å‚æ•°:
            items (list[dict]): è¦ä¿å­˜çš„æ¡ç›®å­—å…¸åˆ—è¡¨ã€‚
        """
        try:
            with open(self.data_file_path, "w", encoding="utf-8") as f:
                json.dump(items, f, ensure_ascii=False, indent=4)
        except IOError:
            print(f"å†™å…¥æ–‡ä»¶ '{self.data_file_path}' å¤±è´¥ã€‚")
        except Exception as e:
            print(f"ä¿å­˜å½“å‰æ¡ç›®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    def get_new_items(
        self, rss_url: str = "https://linux.do/c/welfare/36.rss"
    ) -> list[dict]:
        """
        æ£€æŸ¥ RSS è®¢é˜…æºä¸­ä¸å…ˆå‰å­˜å‚¨çš„æ¡ç›®ç›¸æ¯”æ˜¯å¦æœ‰æ–°æ¡ç›®ã€‚
        ä¿å­˜å½“å‰è·å–çš„è®¢é˜…æ¡ç›®ä»¥ä¾›ä¸‹æ¬¡æ£€æŸ¥ã€‚

        å‚æ•°:
            rss_url (str, å¯é€‰): è¦æ£€æŸ¥çš„ RSS è®¢é˜…æº URLã€‚
                                 é»˜è®¤ä¸º "https://linux.do/c/welfare/36.rss"ã€‚

        è¿”å›:
            list[dict]: æ–°æ¡ç›®çš„åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡ç›®æ˜¯ä¸€ä¸ªåŒ…å« 'title'ã€'link' å’Œ 'pubDate' çš„å­—å…¸ã€‚
                        å¦‚æœæ²¡æœ‰æ–°æ¡ç›®æˆ–è·å–/è§£æå¤±è´¥ï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚
        """
        print(f"\næ­£åœ¨ä» {rss_url} è·å– RSS è®¢é˜…...")
        current_items = self._fetch_and_parse_rss(rss_url)

        if not current_items:
            print("æœªèƒ½è·å–æˆ–è§£æ RSS è®¢é˜…ï¼Œæˆ–è®¢é˜…ä¸ºç©ºã€‚æœªå‘ç°æ–°æ¡ç›®ã€‚")
            return []

        print(f"æˆåŠŸè·å– {len(current_items)} ä¸ªæ¡ç›®ã€‚æ­£åœ¨åŠ è½½å·²å­˜å‚¨çš„æ¡ç›®...")
        stored_guids = self._load_stored_item_guids()
        print(f"å·²åŠ è½½ {len(stored_guids)} ä¸ªå·²å­˜å‚¨æ¡ç›®çš„ GUIDã€‚")

        new_items_info = []

        for item in current_items:
            if item.get("guid") and item["guid"] not in stored_guids:
                new_item = {"title": item["title"], "link": item["link"]}
                if "pubDate" in item and item["pubDate"]:
                    new_item["pubDate"] = item["pubDate"]
                new_items_info.append(new_item)

        if new_items_info:
            print(f"å‘ç° {len(new_items_info)} ä¸ªæ–°æ¡ç›®ã€‚")
        else:
            print("æ²¡æœ‰å‘ç°æ–°æ¡ç›®ã€‚")

        # ä¿å­˜æ‰€æœ‰å½“å‰è·å–çš„æ¡ç›®ï¼ˆåŒ…æ‹¬æ–°çš„å’Œæ—§çš„ï¼‰ï¼Œä»¥ä¾¿ä¸‹æ¬¡è¿è¡Œæ—¶è¿›è¡Œæ¯”è¾ƒ
        print(f"æ­£åœ¨ä¿å­˜ {len(current_items)} ä¸ªå½“å‰æ¡ç›®åˆ° {self.data_file_path}...")
        self._save_current_items(current_items)

        return new_items_info


if __name__ == "__main__":

    load_dotenv()
    cookie = os.getenv("COOKIE", "")
    if not cookie:
        print("COOKIE ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·è®¾ç½®åé‡æ–°è¿è¡Œã€‚")
        exit(1)
    feishu_bot_secret = os.getenv("FEISHU_BOT_SECRET", "")
    if not feishu_bot_secret:
        print("FEISHU_BOT_SECRET ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·è®¾ç½®åé‡æ–°è¿è¡Œã€‚")
        exit(1)
    feishu_bot_url = os.getenv("FEISHU_BOT_URL", "")
    if not feishu_bot_url:
        print("FEISHU_BOT_URL ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·è®¾ç½®åé‡æ–°è¿è¡Œã€‚")
        exit(1)
    # 1. æŒ‡å®šä¸€ä¸ªæœ¬åœ°ç›®å½•æ¥å­˜å‚¨ RSS æ•°æ®
    #    è¯·ç¡®ä¿è¿™ä¸ªç›®å½•æ˜¯å¯å†™çš„ã€‚
    #    è„šæœ¬ä¼šåœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªåä¸º 'rss_monitor_data' çš„å­ç›®å½•ã€‚
    current_script_path = os.path.dirname(os.path.abspath(__file__))
    storage_dir = os.path.join(current_script_path, "rss_monitor_data_output")

    # 2. åˆ›å»º RssMonitor å®ä¾‹
    monitor = RssMonitor(local_storage_path=storage_dir)

    # 3. æŒ‡å®š RSS è®¢é˜… URL
    linuxdo_welfare_rss = "https://linux.do/c/welfare/36.rss"

    print(f"--- é¦–æ¬¡è¿è¡Œæˆ–æ£€æŸ¥ '{linuxdo_welfare_rss}' ---")
    new_posts = monitor.get_new_items(rss_url=linuxdo_welfare_rss)

    if new_posts:
        print("\nå‘ç°ä»¥ä¸‹æ–°å†…å®¹:")
        for i, post in enumerate(new_posts, 1):
            print(f"  æ–°æ¡ç›® {i}:")
            print(f"    æ ‡é¢˜: {post['title']}")
            print(f"    é“¾æ¥: {post['link']}")
            if "pubDate" in post:
                print(f"    å‘å¸ƒæ—¶é—´: {post['pubDate']}")

        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # æ¨é€åˆ°é£ä¹¦
        # æ„å»ºé£ä¹¦å¯Œæ–‡æœ¬å†…å®¹
        post_content_elements = []

        # æ·»åŠ ç¬¬ä¸€è¡Œæ–‡æœ¬å’Œå½“å‰æ—¶é—´
        post_content_elements.append(
            [{"tag": "text", "text": f"ğŸš€ è®ºå›æ›´æ–° (æ¨é€æ—¶é—´: {current_time})"}]
        )

        # ä¸ºæ¯ä¸ªæ–°å¸–å­æ·»åŠ å†…å®¹
        for post in new_posts:
            title_element = [{"tag": "text", "text": f"æ ‡é¢˜: {post['title']}"}]
            link_element = [
                {"tag": "text", "text": "é“¾æ¥: "},
                {"tag": "a", "text": post["link"], "href": post["link"]},
            ]

            # æ·»åŠ å‘å¸ƒæ—¶é—´ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if "pubDate" in post and post["pubDate"]:
                time_element = [{"tag": "text", "text": f"å‘å¸ƒæ—¶é—´: {post['pubDate']}"}]
                post_content_elements.append(title_element)
                post_content_elements.append(link_element)
                post_content_elements.append(time_element)
            else:
                post_content_elements.append(title_element)
                post_content_elements.append(link_element)

            post_content_elements.append(
                [{"tag": "text", "text": "-----------------------"}]
            )  # åˆ†éš”

        feishu("ğŸš€ è®ºå›æ›´æ–°", post_content_elements)
    else:
        print("\nåœ¨æ­¤æ¬¡æ£€æŸ¥ä¸­ï¼Œæ²¡æœ‰å‘ç°æ–°å†…å®¹ï¼Œæˆ–è€…æ‰€æœ‰å†…å®¹éƒ½æ˜¯å·²çŸ¥çš„ã€‚")
