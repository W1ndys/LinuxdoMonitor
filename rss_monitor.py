import xml.etree.ElementTree as ET
import json
import os
from feishu import feishu
import urllib3


class RssMonitor:
    """
    ä¸€ä¸ªç›‘æ§ RSS è®¢é˜…æºå¹¶æå–æ–°å†…å®¹çš„ç±»ã€‚
    """

    def __init__(self, local_storage_path: str):
        """
        åˆå§‹åŒ– RssMonitorã€‚

        å‚æ•°:
            local_storage_path (str): ç”¨äºå­˜å‚¨ RSS æ•°æ®çš„æœ¬åœ°ç›®å½•è·¯å¾„ã€‚
                                      æ•°æ®å°†ä¿å­˜åœ¨æ­¤ç›®å½•ä¸‹çš„ 'rss_feed_data.json' æ–‡ä»¶ä¸­ã€‚
        """
        self.storage_path = local_storage_path
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        os.makedirs(self.storage_path, exist_ok=True)
        self.data_file_path = os.path.join(self.storage_path, "rss_feed_data.json")
        print(
            f"RssMonitor åˆå§‹åŒ–å®Œæ¯•ã€‚æ•°æ®å°†å­˜å‚¨åœ¨: {os.path.abspath(self.data_file_path)}"
        )

    def _fetch_and_parse_rss(self, rss_url: str) -> list[dict]:
        """
        ä»ç»™å®šçš„ URL è·å– RSS è®¢é˜…å†…å®¹å¹¶è§£æã€‚

        å‚æ•°:
            rss_url (str): RSS è®¢é˜…æºçš„ URLã€‚

        è¿”å›:
            list[dict]: åŒ…å«æ¡ç›®ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å« 'title', 'link', å’Œ 'guid'ã€‚
                        å¦‚æœè·å–æˆ–è§£æå¤±è´¥ï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚
        """
        items = []
        try:
            import requests
            import time
            import warnings

            # å¿½ç•¥SSLè­¦å‘Š
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

            # åˆ›å»ºä¼šè¯ä¿æŒè¿æ¥çŠ¶æ€
            session = requests.Session()
            session.verify = False

            # è®¾ç½®ç±»ä¼¼çœŸå®æµè§ˆå™¨çš„headers
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36 Edg/136.0.0.0",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
                "Cache-Control": "max-age=0",
                "Referer": "https://linux.do/",
            }

            # å…ˆè®¿é—®ä¸»ç«™è·å–cookies
            session.get("https://linux.do/", headers=headers, timeout=15)

            # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
            time.sleep(2)

            # è¯·æ±‚RSSé“¾æ¥
            response = session.get(rss_url, headers=headers, timeout=15)

            if response.status_code != 200:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text[:200]}...")
                return []

            content_str = response.text

            if not content_str.strip():
                print("è·å–åˆ°çš„RSSå†…å®¹ä¸ºç©º")
                return []

            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºXML
            if not content_str.startswith("<?xml"):
                print(f"è·å–åˆ°çš„å†…å®¹å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„XML: {content_str[:100]}...")
                # å°è¯•æŸ¥æ‰¾XMLå¼€å§‹ä½ç½®
                xml_start = content_str.find("<?xml")
                if xml_start > 0:
                    content_str = content_str[xml_start:]
                else:
                    print("æœªèƒ½æ‰¾åˆ°XMLå†…å®¹ï¼Œå¯èƒ½æ˜¯é‡åˆ°äº†äººæœºéªŒè¯")
                    print("æ­£åœ¨å°è¯•è§£å†³...")
                    # å°è¯•è§£æHTMLæŸ¥æ‰¾ä¿æŠ¤æ¨¡å¼çš„æç¤º
                    if "just a moment" in content_str.lower():
                        print("æ£€æµ‹åˆ°Cloudflareä¿æŠ¤æˆ–ç±»ä¼¼ä¿æŠ¤æœºåˆ¶")
                    return []

            # è§£æXML
            try:
                root = ET.fromstring(content_str)

                # ä¼˜å…ˆæŸ¥æ‰¾ RSS 2.0 æ ‡å‡†çš„ channel/item
                item_elements = root.findall(".//channel/item")
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯• Atom feed çš„ entry
                if not item_elements:
                    item_elements = root.findall("{http://www.w3.org/2005/Atom}entry")

                print(f"æ‰¾åˆ° {len(item_elements)} ä¸ªitemå…ƒç´ ")

                for item_element in item_elements:
                    title_element = item_element.find("title")
                    title = (
                        title_element.text.strip()
                        if title_element is not None and title_element.text
                        else "N/A"
                    )

                    link_element = item_element.find("link")
                    link = None
                    if link_element is not None:
                        if "href" in link_element.attrib:  # Atom feeds
                            link = link_element.get("href")
                        elif link_element.text:  # RSS
                            link = link_element.text

                    guid_element = item_element.find("guid")  # RSS
                    id_element = item_element.find(
                        "{http://www.w3.org/2005/Atom}id"
                    )  # Atom

                    guid = None
                    if guid_element is not None and guid_element.text:
                        guid = guid_element.text.strip()
                    elif id_element is not None and id_element.text:
                        guid = id_element.text.strip()

                    # å¦‚æœ guid ä¸å­˜åœ¨ï¼Œä½¿ç”¨ link ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
                    if not guid and link:
                        guid = link.strip()

                    if title and link and guid:
                        items.append(
                            {"title": title, "link": link.strip(), "guid": guid}
                        )
                    elif title and guid and not link:
                        items.append({"title": title, "link": "N/A", "guid": guid})

            except ET.ParseError as e:
                print(f"è§£æ XML å¤±è´¥: {e}")
                print(f"å†…å®¹ç‰‡æ®µ: {content_str[:200]}")

        except requests.exceptions.RequestException as e:
            print(f"è¯·æ±‚å¼‚å¸¸ ({rss_url}): {e}")
        except Exception as e:
            print(f"å¤„ç† RSS æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ ({rss_url}): {e}")

        return items

    def _load_stored_item_guids(self) -> set[str]:
        """
        ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å…ˆå‰å­˜å‚¨çš„æ¡ç›®çš„ GUIDã€‚

        è¿”å›:
            set[str]: å­˜å‚¨çš„ GUID é›†åˆã€‚å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è¯»å–/è§£æï¼Œåˆ™è¿”å›ç©ºé›†åˆã€‚
        """
        stored_guids = set()
        if os.path.exists(self.data_file_path):
            try:
                with open(self.data_file_path, "r", encoding="utf-8") as f:
                    stored_items = json.load(f)
                for item in stored_items:
                    # ç¡®ä¿ 'guid' é”®å­˜åœ¨
                    if isinstance(item, dict) and "guid" in item and item["guid"]:
                        stored_guids.add(item["guid"])
            except json.JSONDecodeError:
                print(
                    f"è§£æ JSON æ–‡ä»¶ '{self.data_file_path}' å¤±è´¥ã€‚å°†è§†ä¸ºç©ºç™½å†å²è®°å½•ã€‚"
                )
            except IOError:
                print(f"è¯»å–æ–‡ä»¶ '{self.data_file_path}' å¤±è´¥ã€‚å°†è§†ä¸ºç©ºç™½å†å²è®°å½•ã€‚")
        return stored_guids

    def _save_current_items(self, items: list[dict]):
        """
        å°†å½“å‰è·å–çš„æ¡ç›®åˆ—è¡¨ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ã€‚

        å‚æ•°:
            items (list[dict]): è¦ä¿å­˜çš„æ¡ç›®å­—å…¸åˆ—è¡¨ã€‚
        """
        try:
            with open(self.data_file_path, "w", encoding="utf-8") as f:
                json.dump(items, f, ensure_ascii=False, indent=4)
        except IOError:
            print(f"å†™å…¥æ–‡ä»¶ '{self.data_file_path}' å¤±è´¥ã€‚")
        except Exception as e:
            print(f"ä¿å­˜å½“å‰æ¡ç›®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    def get_new_items(
        self, rss_url: str = "https://linux.do/c/welfare/36.rss"
    ) -> list[dict]:
        """
        æ£€æŸ¥ RSS è®¢é˜…æºä¸­ä¸å…ˆå‰å­˜å‚¨çš„æ¡ç›®ç›¸æ¯”æ˜¯å¦æœ‰æ–°æ¡ç›®ã€‚
        ä¿å­˜å½“å‰è·å–çš„è®¢é˜…æ¡ç›®ä»¥ä¾›ä¸‹æ¬¡æ£€æŸ¥ã€‚

        å‚æ•°:
            rss_url (str, å¯é€‰): è¦æ£€æŸ¥çš„ RSS è®¢é˜…æº URLã€‚
                                 é»˜è®¤ä¸º "https://linux.do/c/welfare/36.rss"ã€‚

        è¿”å›:
            list[dict]: æ–°æ¡ç›®çš„åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡ç›®æ˜¯ä¸€ä¸ªåŒ…å« 'title' å’Œ 'link' çš„å­—å…¸ã€‚
                        å¦‚æœæ²¡æœ‰æ–°æ¡ç›®æˆ–è·å–/è§£æå¤±è´¥ï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚
        """
        print(f"\næ­£åœ¨ä» {rss_url} è·å– RSS è®¢é˜…...")
        current_items = self._fetch_and_parse_rss(rss_url)

        if not current_items:
            print("æœªèƒ½è·å–æˆ–è§£æ RSS è®¢é˜…ï¼Œæˆ–è®¢é˜…ä¸ºç©ºã€‚æœªå‘ç°æ–°æ¡ç›®ã€‚")
            return []

        print(f"æˆåŠŸè·å– {len(current_items)} ä¸ªæ¡ç›®ã€‚æ­£åœ¨åŠ è½½å·²å­˜å‚¨çš„æ¡ç›®...")
        stored_guids = self._load_stored_item_guids()
        print(f"å·²åŠ è½½ {len(stored_guids)} ä¸ªå·²å­˜å‚¨æ¡ç›®çš„ GUIDã€‚")

        new_items_info = []

        for item in current_items:
            if item.get("guid") and item["guid"] not in stored_guids:
                new_items_info.append({"title": item["title"], "link": item["link"]})

        if new_items_info:
            print(f"å‘ç° {len(new_items_info)} ä¸ªæ–°æ¡ç›®ã€‚")
        else:
            print("æ²¡æœ‰å‘ç°æ–°æ¡ç›®ã€‚")

        # ä¿å­˜æ‰€æœ‰å½“å‰è·å–çš„æ¡ç›®ï¼ˆåŒ…æ‹¬æ–°çš„å’Œæ—§çš„ï¼‰ï¼Œä»¥ä¾¿ä¸‹æ¬¡è¿è¡Œæ—¶è¿›è¡Œæ¯”è¾ƒ
        print(f"æ­£åœ¨ä¿å­˜ {len(current_items)} ä¸ªå½“å‰æ¡ç›®åˆ° {self.data_file_path}...")
        self._save_current_items(current_items)

        return new_items_info


if __name__ == "__main__":
    # --- ä½¿ç”¨ç¤ºä¾‹ ---

    # 1. æŒ‡å®šä¸€ä¸ªæœ¬åœ°ç›®å½•æ¥å­˜å‚¨ RSS æ•°æ®
    #    è¯·ç¡®ä¿è¿™ä¸ªç›®å½•æ˜¯å¯å†™çš„ã€‚
    #    è„šæœ¬ä¼šåœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªåä¸º 'rss_monitor_data' çš„å­ç›®å½•ã€‚
    current_script_path = os.path.dirname(os.path.abspath(__file__))
    storage_dir = os.path.join(current_script_path, "rss_monitor_data_output")

    # 2. åˆ›å»º RssMonitor å®ä¾‹
    monitor = RssMonitor(local_storage_path=storage_dir)

    # 3. æŒ‡å®š RSS è®¢é˜… URL
    linuxdo_welfare_rss = "https://linux.do/c/welfare/36.rss"

    print(f"--- é¦–æ¬¡è¿è¡Œæˆ–æ£€æŸ¥ '{linuxdo_welfare_rss}' ---")
    new_posts = monitor.get_new_items(rss_url=linuxdo_welfare_rss)

    if new_posts:
        print("\nå‘ç°ä»¥ä¸‹æ–°å†…å®¹:")
        for i, post in enumerate(new_posts, 1):
            print(f"  æ–°æ¡ç›® {i}:")
            print(f"    æ ‡é¢˜: {post['title']}")
            print(f"    é“¾æ¥: {post['link']}")
        # æ¨é€åˆ°é£ä¹¦
        # æ„å»ºé£ä¹¦å¯Œæ–‡æœ¬å†…å®¹
        post_content_elements = []

        # æ·»åŠ ç¬¬ä¸€è¡Œæ–‡æœ¬
        post_content_elements.append([{"tag": "text", "text": "ğŸš€ è®ºå›æ›´æ–°"}])

        # ä¸ºæ¯ä¸ªæ–°å¸–å­æ·»åŠ å†…å®¹
        for post in new_posts:
            title_element = [{"tag": "text", "text": f"æ ‡é¢˜: {post['title']}"}]
            link_element = [
                {"tag": "text", "text": "é“¾æ¥: "},
                {"tag": "a", "text": post["link"], "href": post["link"]},
            ]
            post_content_elements.append(title_element)
            post_content_elements.append(link_element)
            post_content_elements.append(
                [{"tag": "text", "text": "-----------------------"}]
            )  # åˆ†éš”

        feishu("ğŸš€ è®ºå›æ›´æ–°", post_content_elements)
    else:
        print("\nåœ¨æ­¤æ¬¡æ£€æŸ¥ä¸­ï¼Œæ²¡æœ‰å‘ç°æ–°å†…å®¹ï¼Œæˆ–è€…æ‰€æœ‰å†…å®¹éƒ½æ˜¯å·²çŸ¥çš„ã€‚")
